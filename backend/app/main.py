"""
MCP Platform - FastAPI Main Application
é›†æˆçŸ¥è¯†å›¾è°±ã€å‘é‡æ£€ç´¢ã€RAGé—®ç­”çš„å®Œæ•´å¹³å°
"""
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Optional

from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from loguru import logger
from dotenv import load_dotenv

from app.parsers.pdf_parser import PDFParser
from app.parsers.word_parser import WordParser
from app.nlp.segmenter import TextSegmenter
from app.nlp.ner import SimpleNER, SpacyNER, RelationExtractor
from app.models.schemas import DocumentMetadata, ParsedDocument
from app.kg.neo4j_manager import Neo4jManager
from app.vector.vector_store import VectorStoreManager
from app.rag.rag_engine import RAGEngine

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(
    title="MCP Platform",
    description="æ•°å­—å›¾ä¹¦ç®¡ç†å‘˜å¼çŸ¥è¯†å›¾è°±å¹³å° API - æ”¯æŒæ–‡æ¡£è§£æã€çŸ¥è¯†å›¾è°±ã€å‘é‡æ£€ç´¢ã€RAGé—®ç­”",
    version="0.2.0"
)

# CORSé…ç½®ï¼ˆå…è®¸å‰ç«¯è·¨åŸŸè®¿é—®ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path("./uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# ==================== åˆå§‹åŒ–å„ä¸ªæ¨¡å— ====================

# æ–‡ä»¶è§£æå™¨
pdf_parser = PDFParser()
word_parser = WordParser()
text_segmenter = TextSegmenter(max_chunk_size=500, overlap=50)

# NERå¼•æ“ï¼ˆå°è¯•ä½¿ç”¨SpaCyï¼Œå¤±è´¥åˆ™ä½¿ç”¨SimpleNERï¼‰
ner_engine = SpacyNER()
if not ner_engine.available:
    logger.warning("SpaCy not available, falling back to SimpleNER")
    ner_engine = SimpleNER()

relation_extractor = RelationExtractor()

# çŸ¥è¯†å›¾è°±ç®¡ç†å™¨ï¼ˆNeo4jï¼‰
try:
    kg_manager = Neo4jManager()
    if kg_manager.connected:
        kg_manager.create_constraints()
except Exception as e:
    logger.warning(f"Knowledge Graph initialization failed: {e}")
    kg_manager = None

# å‘é‡å­˜å‚¨ç®¡ç†å™¨ï¼ˆChromaDBï¼‰
try:
    vector_store = VectorStoreManager()
except Exception as e:
    logger.error(f"Vector Store initialization failed: {e}")
    vector_store = None

# RAGé—®ç­”å¼•æ“
try:
    rag_engine = RAGEngine(
        vector_store=vector_store,
        kg_manager=kg_manager
    )
except Exception as e:
    logger.warning(f"RAG Engine initialization failed: {e}")
    rag_engine = None

# å†…å­˜æ–‡æ¡£å­˜å‚¨ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
documents_store = {}

logger.info("="*60)
logger.info("MCP Platform Initialized")
logger.info(f"  - Knowledge Graph (Neo4j): {'âœ“' if kg_manager and kg_manager.connected else 'âœ—'}")
logger.info(f"  - Vector Store (ChromaDB): {'âœ“' if vector_store and vector_store.available else 'âœ—'}")
logger.info(f"  - RAG Engine (OpenAI): {'âœ“' if rag_engine and rag_engine.available else 'âœ—'}")
logger.info("="*60)


# ==================== åŸºç¡€API ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Welcome to MCP Platform API",
        "version": "0.2.0",
        "docs": "/docs",
        "features": {
            "file_parsing": True,
            "nlp_processing": True,
            "knowledge_graph": kg_manager is not None and kg_manager.connected,
            "vector_search": vector_store is not None and vector_store.available,
            "rag_qa": rag_engine is not None and rag_engine.available
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    kg_stats = kg_manager.get_stats() if kg_manager else {"connected": False}
    vector_stats = vector_store.get_stats() if vector_store else {"available": False}

    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "pdf_parser": "available",
            "word_parser": "available",
            "ner_engine": "spacy" if isinstance(ner_engine, SpacyNER) and ner_engine.available else "simple",
            "knowledge_graph": {
                "status": "connected" if kg_stats.get("connected") else "disconnected",
                "nodes": kg_stats.get("nodes", 0),
                "relationships": kg_stats.get("relationships", 0)
            },
            "vector_store": {
                "status": "available" if vector_stats.get("available") else "unavailable",
                "total_chunks": vector_stats.get("total_chunks", 0)
            },
            "rag_engine": "available" if rag_engine and rag_engine.available else "unavailable"
        }
    }


# ==================== æ–‡æ¡£ä¸Šä¼ ä¸è§£æ ====================

@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """
    ä¸Šä¼ æ–‡ä»¶å¹¶å®Œæ•´å¤„ç†ï¼ˆè§£æã€NERã€çŸ¥è¯†å›¾è°±ã€å‘é‡åŒ–ï¼‰

    æ”¯æŒçš„æ–‡ä»¶ç±»å‹: PDF, DOCX
    """
    try:
        # ç”Ÿæˆæ–‡æ¡£ID
        document_id = str(uuid.uuid4())

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ['.pdf', '.docx', '.doc']:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}. ä»…æ”¯æŒ PDF å’Œ DOCX"
            )

        # ä¿å­˜æ–‡ä»¶
        file_path = UPLOAD_DIR / f"{document_id}{file_ext}"
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"File uploaded: {file.filename} -> {file_path}")

        # 1. è§£ææ–‡ä»¶
        if file_ext == '.pdf':
            parse_result = pdf_parser.parse(str(file_path))
        else:
            parse_result = word_parser.parse(str(file_path))

        if parse_result['status'] == 'error':
            raise HTTPException(status_code=500, detail=parse_result.get('error', 'Parse error'))

        text = parse_result['text']

        # 2. æ–‡æœ¬åˆ†æ®µ
        chunks = text_segmenter.segment(text, document_id)

        # 3. å®ä½“è¯†åˆ«
        entities = ner_engine.extract_entities(text)

        # 4. å…³ç³»æŠ½å–
        relations = relation_extractor.extract_relations(text, entities)

        # 5. å­˜å‚¨åˆ°çŸ¥è¯†å›¾è°±
        kg_success = False
        if kg_manager and kg_manager.connected:
            # åˆ›å»ºæ–‡æ¡£èŠ‚ç‚¹
            metadata = {
                **parse_result['metadata'],
                "file_type": file_ext[1:]
            }
            kg_manager.create_document_node(document_id, metadata)

            # æ‰¹é‡åˆ›å»ºå®ä½“èŠ‚ç‚¹
            kg_manager.batch_create_entities(entities, document_id)

            # æ‰¹é‡åˆ›å»ºå…³ç³»
            kg_manager.batch_create_relations(relations)

            kg_success = True
            logger.info(f"âœ“ Saved to Knowledge Graph: {len(entities)} entities, {len(relations)} relations")

        # 6. å‘é‡åŒ–å¹¶å­˜å‚¨
        vector_success = False
        if vector_store and vector_store.available:
            vector_store.add_chunks(chunks, document_id)
            vector_success = True
            logger.info(f"âœ“ Saved to Vector Store: {len(chunks)} chunks")

        # æ„å»ºå“åº”
        parsed_doc = {
            "document_id": document_id,
            "file_name": file.filename,
            "file_type": file_ext[1:],
            "text_length": len(text),
            "chunks_count": len(chunks),
            "entities_count": len(entities),
            "relations_count": len(relations),
            "metadata": parse_result['metadata'],
            "processing": {
                "knowledge_graph": kg_success,
                "vector_store": vector_success
            },
            "status": "success"
        }

        # ä¿å­˜åˆ°å†…å­˜å­˜å‚¨
        documents_store[document_id] = {
            **parsed_doc,
            "text": text,
            "chunks": chunks,
            "entities": entities,
            "relations": relations,
            "file_path": str(file_path)
        }

        logger.info(f"Document processed successfully: {document_id}")

        return JSONResponse(content=parsed_doc)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error uploading file: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== æ–‡æ¡£ç®¡ç†API ====================

@app.get("/api/documents")
async def list_documents():
    """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
    docs = []
    for doc_id, doc in documents_store.items():
        docs.append({
            "document_id": doc_id,
            "file_name": doc["file_name"],
            "file_type": doc["file_type"],
            "text_length": doc["text_length"],
            "entities_count": doc["entities_count"],
            "chunks_count": doc["chunks_count"]
        })

    return JSONResponse(content={
        "total": len(docs),
        "documents": docs
    })


@app.get("/api/documents/{document_id}")
async def get_document(document_id: str):
    """è·å–æ–‡æ¡£è¯¦æƒ…"""
    if document_id not in documents_store:
        raise HTTPException(status_code=404, detail="Document not found")

    doc = documents_store[document_id]

    return JSONResponse(content={
        "document_id": document_id,
        "file_name": doc["file_name"],
        "file_type": doc["file_type"],
        "text_length": doc["text_length"],
        "chunks_count": doc["chunks_count"],
        "entities_count": doc["entities_count"],
        "relations_count": doc["relations_count"],
        "metadata": doc["metadata"]
    })


@app.get("/api/documents/{document_id}/text")
async def get_document_text(document_id: str):
    """è·å–æ–‡æ¡£å…¨æ–‡"""
    if document_id not in documents_store:
        raise HTTPException(status_code=404, detail="Document not found")

    return JSONResponse(content={
        "document_id": document_id,
        "text": documents_store[document_id]["text"]
    })


@app.get("/api/documents/{document_id}/entities")
async def get_entities(document_id: str):
    """è·å–æ–‡æ¡£çš„æ‰€æœ‰å®ä½“"""
    if document_id not in documents_store:
        raise HTTPException(status_code=404, detail="Document not found")

    entities = documents_store[document_id]["entities"]

    return JSONResponse(content={
        "document_id": document_id,
        "entities_count": len(entities),
        "entities": entities
    })


@app.get("/api/documents/{document_id}/relations")
async def get_relations(document_id: str):
    """è·å–æ–‡æ¡£çš„æ‰€æœ‰å…³ç³»"""
    if document_id not in documents_store:
        raise HTTPException(status_code=404, detail="Document not found")

    relations = documents_store[document_id]["relations"]

    return JSONResponse(content={
        "document_id": document_id,
        "relations_count": len(relations),
        "relations": relations[:100]  # é™åˆ¶è¿”å›æ•°é‡
    })


@app.delete("/api/documents/{document_id}")
async def delete_document(document_id: str):
    """åˆ é™¤æ–‡æ¡£ï¼ˆåŒ…æ‹¬æ–‡ä»¶ã€å‘é‡ã€çŸ¥è¯†å›¾è°±ï¼‰"""
    if document_id not in documents_store:
        raise HTTPException(status_code=404, detail="Document not found")

    # åˆ é™¤æ–‡ä»¶
    file_path = documents_store[document_id]["file_path"]
    if os.path.exists(file_path):
        os.remove(file_path)

    # åˆ é™¤å‘é‡
    if vector_store:
        vector_store.delete_document(document_id)

    # TODO: åˆ é™¤çŸ¥è¯†å›¾è°±ä¸­çš„æ–‡æ¡£èŠ‚ç‚¹

    # ä»å†…å­˜ä¸­åˆ é™¤
    del documents_store[document_id]

    logger.info(f"Document deleted: {document_id}")

    return JSONResponse(content={"message": "Document deleted successfully"})


# ==================== çŸ¥è¯†å›¾è°±API ====================

@app.get("/api/kg/stats")
async def get_kg_stats():
    """è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
    if not kg_manager or not kg_manager.connected:
        raise HTTPException(status_code=503, detail="Knowledge Graph not available")

    stats = kg_manager.get_stats()
    return JSONResponse(content=stats)


@app.get("/api/kg/graph/{document_id}")
async def get_document_graph(document_id: str):
    """è·å–æ–‡æ¡£çš„çŸ¥è¯†å›¾è°±"""
    if not kg_manager or not kg_manager.connected:
        raise HTTPException(status_code=503, detail="Knowledge Graph not available")

    graph_data = kg_manager.get_document_graph(document_id)
    return JSONResponse(content=graph_data)


@app.get("/api/kg/entity/{entity_text}")
async def get_entity_subgraph(
    entity_text: str,
    max_depth: int = Query(2, ge=1, le=5),
    limit: int = Query(50, ge=1, le=200)
):
    """è·å–å®ä½“çš„é‚»å±…å­å›¾"""
    if not kg_manager or not kg_manager.connected:
        raise HTTPException(status_code=503, detail="Knowledge Graph not available")

    subgraph = kg_manager.get_entity_neighbors(entity_text, max_depth, limit)
    return JSONResponse(content=subgraph)


@app.get("/api/kg/search")
async def search_entities(
    label: str = Query(..., description="å®ä½“æ ‡ç­¾"),
    limit: int = Query(20, ge=1, le=100)
):
    """æŒ‰æ ‡ç­¾æœç´¢å®ä½“"""
    if not kg_manager or not kg_manager.connected:
        raise HTTPException(status_code=503, detail="Knowledge Graph not available")

    entities = kg_manager.search_entities_by_label(label, limit)
    return JSONResponse(content={"entities": entities})


# ==================== å‘é‡æ£€ç´¢API ====================

@app.get("/api/search")
async def semantic_search(
    query: str = Query(..., min_length=1),
    top_k: int = Query(5, ge=1, le=20),
    document_id: Optional[str] = None
):
    """è¯­ä¹‰æœç´¢"""
    if not vector_store or not vector_store.available:
        raise HTTPException(status_code=503, detail="Vector Store not available")

    if document_id:
        results = vector_store.search_by_document(query, document_id, top_k)
    else:
        results = vector_store.search(query, top_k)

    return JSONResponse(content={
        "query": query,
        "results_count": len(results),
        "results": results
    })


@app.get("/api/search/hybrid")
async def hybrid_search(
    query: str = Query(..., min_length=1),
    top_k: int = Query(10, ge=1, le=20),
    semantic_weight: float = Query(0.7, ge=0.0, le=1.0)
):
    """æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰"""
    if not vector_store or not vector_store.available:
        raise HTTPException(status_code=503, detail="Vector Store not available")

    results = vector_store.hybrid_search(query, top_k, semantic_weight)

    return JSONResponse(content={
        "query": query,
        "results_count": len(results),
        "results": results
    })


# ==================== RAGé—®ç­”API ====================

@app.post("/api/qa/ask")
async def ask_question(
    question: str = Query(..., min_length=1),
    document_id: Optional[str] = None,
    top_k: int = Query(5, ge=1, le=10),
    use_hybrid: bool = Query(True),
    include_graph: bool = Query(False)
):
    """RAGé—®ç­”"""
    if not rag_engine:
        raise HTTPException(status_code=503, detail="RAG Engine not available")

    result = rag_engine.ask(
        question=question,
        document_id=document_id,
        top_k=top_k,
        use_hybrid=use_hybrid,
        include_graph=include_graph
    )

    return JSONResponse(content=result)


@app.post("/api/qa/summarize/{document_id}")
async def summarize_document(
    document_id: str,
    max_length: int = Query(500, ge=100, le=2000)
):
    """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
    if not rag_engine:
        raise HTTPException(status_code=503, detail="RAG Engine not available")

    result = rag_engine.summarize_document(document_id, max_length)

    return JSONResponse(content=result)


# ==================== LLMæ¨¡å‹ç®¡ç†API ====================

@app.get("/api/llm/providers")
async def get_llm_providers():
    """è·å–æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†"""
    if not rag_engine or not rag_engine.available:
        return JSONResponse(content={
            "providers": [],
            "current": None,
            "message": "No LLM providers configured"
        })

    providers = rag_engine.llm_manager.get_available_providers()
    current = rag_engine.llm_manager.get_current_info()

    return JSONResponse(content={
        "providers": providers,
        "current": current
    })


@app.get("/api/llm/providers/all")
async def get_all_llm_providers():
    """è·å–æ‰€æœ‰æ”¯æŒçš„LLMæä¾›å•†ï¼ˆåŒ…æ‹¬æœªé…ç½®çš„ï¼‰"""
    if not rag_engine:
        from app.rag.llm_providers import LLMProviderManager
        temp_manager = LLMProviderManager()
        providers = temp_manager.get_all_providers()
    else:
        providers = rag_engine.llm_manager.get_all_providers()

    return JSONResponse(content={
        "providers": providers
    })


@app.post("/api/llm/test")
async def test_llm_provider(
    provider: str = Query(..., description="æä¾›å•†ID (openai/qwen/deepseek)"),
    api_key: str = Query(..., description="APIå¯†é’¥"),
    model: Optional[str] = Query(None, description="æ¨¡å‹åç§°")
):
    """æµ‹è¯•LLMæä¾›å•†çš„API Key"""
    if not rag_engine:
        raise HTTPException(status_code=503, detail="RAG Engine not available")

    result = rag_engine.llm_manager.test_provider(provider, api_key, model)

    if result["success"]:
        return JSONResponse(content=result)
    else:
        raise HTTPException(status_code=400, detail=result["message"])


@app.post("/api/llm/config")
async def config_llm_provider(
    provider: str = Query(..., description="æä¾›å•†ID (openai/qwen/deepseek)"),
    api_key: str = Query(..., description="APIå¯†é’¥"),
    model: Optional[str] = Query(None, description="æ¨¡å‹åç§°"),
    set_as_current: bool = Query(True, description="æ˜¯å¦è®¾ä¸ºå½“å‰ä½¿ç”¨")
):
    """é…ç½®LLMæä¾›å•†ï¼ˆåŠ¨æ€æ·»åŠ /æ›´æ–°ï¼‰"""
    if not rag_engine:
        raise HTTPException(status_code=503, detail="RAG Engine not available")

    # æ·»åŠ æˆ–æ›´æ–°æä¾›å•†
    success = rag_engine.llm_manager.add_or_update_provider(provider, api_key, model)

    if not success:
        raise HTTPException(status_code=400, detail=f"Failed to configure provider {provider}")

    # å¦‚æœéœ€è¦ï¼Œè®¾ç½®ä¸ºå½“å‰ä½¿ç”¨
    if set_as_current:
        rag_engine.llm_manager.set_provider(provider, model)

    current = rag_engine.llm_manager.get_current_info()
    logger.info(f"LLM provider configured: {current['name']} ({current['model']})")

    return JSONResponse(content={
        "success": True,
        "current": current,
        "message": f"Successfully configured {current['name']}"
    })


@app.post("/api/llm/switch")
async def switch_llm_provider(
    provider: str = Query(..., description="æä¾›å•†ID (openai/qwen/deepseek)"),
    model: Optional[str] = Query(None, description="æ¨¡å‹åç§°")
):
    """åˆ‡æ¢LLMæä¾›å•†å’Œæ¨¡å‹"""
    if not rag_engine or not rag_engine.available:
        raise HTTPException(status_code=503, detail="RAG Engine not available")

    success = rag_engine.llm_manager.set_provider(provider, model)

    if success:
        current = rag_engine.llm_manager.get_current_info()
        logger.info(f"LLM provider switched to {current['name']} ({current['model']})")
        return JSONResponse(content={
            "success": True,
            "current": current,
            "message": f"Successfully switched to {current['name']}"
        })
    else:
        raise HTTPException(status_code=400, detail=f"Provider {provider} not available")


@app.get("/api/llm/current")
async def get_current_llm():
    """è·å–å½“å‰ä½¿ç”¨çš„LLMæä¾›å•†"""
    if not rag_engine or not rag_engine.available:
        return JSONResponse(content={
            "provider": "none",
            "model": "none",
            "name": "æœªé…ç½®"
        })

    current = rag_engine.llm_manager.get_current_info()
    return JSONResponse(content=current)


# ==================== å¯åŠ¨ä¸å…³é—­ ====================

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ MCP Platform API Server started")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    if kg_manager:
        kg_manager.close()
    logger.info("ğŸ‘‹ MCP Platform API Server stopped")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
